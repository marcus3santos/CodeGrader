#+TITLE: CodeGrader

CodeGrader is an automated grader for lisp programming exercises where
the students' solutions have been exported from D2L.

* Dependencies

- Follow the instructions available [[https://marcus3santos.github.io/lisp-ide.html][here to install the Lisp programming environment]].
  
* Installation

Type the commands below an a linux or Mac terminal:
  #+begin_src shell
   cd ~/quicklisp/local-projects/
   git clone https://github.com/marcus3santos/codegrader.git  
  #+end_src

* Usage

** Marking

1. [ /This is step is not necessary if you are assessing an "ungraded" examination (i.e., an assessment
   whose weight is zero)/ ] On D2L, export the students' *assignment grades* *to a CSV
   file*. When generating this file, select the following /Export
   Options/:
  - Username
  - Points grade
  - Last name
  - First name
  Below is an example of a CSV file exported by D2L:
  #+begin_example
     Username,Last Name,First Name,Lab 0X Points Grade <Course  Data>,End-of-Line-Indicator 
     #TTiger,Tigertongue,Tim,,#
     #Patrick97,Pearson,Patrick,,#
     #Towhander,Twohands,Tony,,#
     #Zain1997,Zodson,Zain,,#
     #Coopercat,Cooper,Cain,,#
     #Hammermann,Odinson,Thor,,#
     #CastleSword03,Vampireson,Alucard,,#
     #TarkovIsAwesone,Handerson,Timb,,#
  #+end_example
  For more information, visit [[https://www.torontomu.ca/courses/instructors/tutorials/grades/grades-export-import/]]
2. On D2L, download the assignment solutions submitted by the
   students. D2L will generate a compressed zip. Do not unzip the file. For more information, visit
   [[https://www.torontomu.ca/courses/instructors/tutorials/assignments/assignment-submissions/]]. Make
   sure you have downloaded *all* submissions.
3. Prepare the *test cases lisp file* for the assignment you want to
   mark. Your instructor has already shared this file with you.
4. Launch Emacs and then press *M-x* and type /Slime/ and press Enter.
1. To load the codegrader, type the following commands on the REPL:
   #+begin_src lisp
     CL-USER> (ql:quickload :codegrader)
   #+end_src
2. To run the students'
   solutions through CodeGrader, type the command below on the CodeGrader REPL: (NOTE: once you
   launch CodeGrader, it will start executing the students'
   solutions; consequently, it will display on the REPL buffer all
   error/warning messages and output generated by the student's solution. CodeGrader
   will be done marking when you see the message =Exam grading complete!= displayed on the REPL window buffer.)
   #+begin_src lisp
     CL-USER> (cg:grade-it submissions tests-folder results-folder exam-grades-export-file)
   #+end_src
   where:
   - ~submissions~ is a string representing the full path and name of the zipped file generated by D2L containing the students' submissions, e.g., ~/Users/johndoe/Downloads/LabXX-XX.zip~
   - ~test-folder~ is a string representing the full path for the test cases folder.
   - ~results-folder~ is a string representing the full path for a folder
    where you want codegrader to store the results (the students'
    marks and log files). For example, if you provide the path
    #+begin_example
    "/Users/johndoe/A1/"
    #+end_example
    then CodeGrader will create its
    files/subfolders inside folder ~/Users/johndoe/A1/~.
   - (optional) ~exam-grades-export-file~ is a string representing the full path for
     the D2L exam grades exported by D2L
    
** Output

CodeGrader generates the following files in the =results= folder (see above):
- A csv spreadsheet file called ~grades.csv~  This is a D2L-importable
  grades file and it is created based on the ~exam-grades-export-file~ argument optionally
  provided by the user (see items 1 and 2 above). Below is an example of
  such files:
   #+begin_example
   Username,Last Name,First Name,Lab 0X Points Grade <Course Data>,End-of-Line-Indicator
   #TTiger,Tigertongue,Tim,100.0,# 
   #Patrick97,Pearson,Patrick,72.5,#
   #Towhander,Twohands,Tony,100.0,#
   #Zain1997,Zodson,Zain,95.5,#
   #Coopercat,Cooper,Cain,100.0,#
   #Hammermann,Odinson,Thor,0.0,#
   #+end_example
   Note:
   - If a student exists in the exported file but not in the
     submissions folder, then the respective grades will
     not be included in the generated in the respective csv files.
- A Feedback folder that holds feedback files for the students. The
  general structure is like this: Consider Timb Handerson who did not
  get a full grade. His feedback file will be as such:
  #+begin_example
  Feedback on your assignment solution

  Unit test results:
  
  ((Pass TEST-DEPOSIT (EQUAL (DEPOSIT 20) 130))
   (Pass TEST-DEPOSIT (EQUAL (DEPOSIT 10) 110))
   (Pass TEST-DEPOSIT (NOT (DEPOSIT 10001)))
   (Fail TEST-WITHDRAW (EQUAL (WITHDRAW 60) 10))
   (Pass TEST-WITHDRAW (NOT (WITHDRAW 80)))
   (Pass TEST-WITHDRAW (NOT (WITHDRAW 10001)))
   (Fail TEST-WITHDRAW (EQUAL (WITHDRAW 20) 70))
   (Fail TEST-WITHDRAW (EQUAL (WITHDRAW 10) 90)))
  #+end_example
- A zipped version of the feedback folder. To be uploaded into D2L.

The log file *codegrader-history/log.txt* located in the root of the
user's home directory contains historical information about the
evaluation of students' assignments.

** Test cases
Test cases must follow a specific format and have a specific file name in order to be used within
CodeGrader.  As an example, suppose the exam requires the
students to submit a file called *q1.lisp* that includes two functions: a ~fact~
function that gives the factorial of a number, and a ~avg~ function
that gives the average of a list of numbers. Moreover, suppose also
that that students are not allowed to use functions FIND and COUNT in
their solutions. Then, the test cases lisp file will be something like
this:
#+begin_src lisp
  (forbidden-funcions :penalty 0.75 :functions '(find count))
  
  (deftest test-fact ()
    (check
      (equal (fact 5) 120)
      (equal (fact 6) 720)
      (equal (fact 7) 5040)
  
  (deftest test-avg ()
    (check
      (equal (avg '(5 8 10 2 12)) 7.4)
      (equal (avg '(0 0 0 0 0 0)) 0)
      (equal (avg '(1 2 0)) 1)
  
  (defun unit-test ()
    "Calls the test cases and 'forgets' the functions that were tested."
    (test-fact)
    (fmakunbound 'fact) ; Removes the function definition from the global environment,
                        ; so the next time around the unit test is done on a freshly loaded version of this function.
    (test-avg)
    (fmakunbound 'avg))
  
  (unit-test) 
#+end_src
Notice: you can include more complex forms of tests, but the general idea is that each argument of CHECK has to be a selfcontained form, i.e., any variables used in it should be defined within the form. For example, below is a test case for a function HT-DELETE that deletes an item from a hash table
#+begin_src lisp
(deftest test-ht-delete ()
  (check
    (equal (let ((*ht* (ht-create '((1 1) (2 2) (3 3) (4 4) (5 5) (6 6)))))
	     (ht-delete 4 *ht*)
	     (ht-get 4 *ht*))  ; accessing a deleted item
	   nil)
    (equal (let ((*ht* (ht-create '((1 1) (2 2) (3 3) (4 4) (5 5) (6 6)))))
	     (ht-delete 4 *ht*)
	     (ht-delete 4 *ht*))  ; deleting an already deleted item
	   nil)
    (equal (let ((*ht* (ht-create '((1 1) (2 2) (3 3) (4 4) (5 5) (6 6)))))
	     (ht-add "a" 44 *ht*)
	     (ht-delete "a" *ht*))  
	   44)))
  
#+end_src

Any errors that the student's solution could raise during runtime will
be handled by CodeGrader and reported as appropriate.

** Other functions

In case you wish to mark one specific submission or test your test
case file, you can use the following function:
#+begin_example
grade-code (student-solution test-cases-dir)
---------------------------------------------------
Description:  Loads the student-solution file, loads the test cases, runs
              the test cases, and returns the percentage of correct results over total results

Inputs:       1) student-solution [string]: The directory for the solution of the student.
              2) test-cases-dir [string]: The directory for the test cases file. This will be used to test the solution of the students for the current assignment.

Outputs:      [list] A list of the following:
              1) [string] The grade of the student.
              2) [string] A comment that describes if there was a runtime error while loading the student submission or not
              3) [string] A description of what happened during runtime (from exceptions to conditions to whatever) 
              4) [list] The results of marking each of the test cases.

Side-effects: This function utilizes the global variable *results* while running. In the beginning by reseting it to nil, and at the end by updating it with the current
              student's submission results.
---------------------------------------------------
#+end_example

Usage Example: Say there was a student that you want to mark their
submissions independantly from the other students. You can simply take
their lisp submission file, say ~"/home/John/mysol.lisp"~ , and the
test cases lisp file "/home/john/test-cases.lisp"~. You would use 
CodeGrader as follows: (assuming you have already installed CodeGrader
as shown above)
#+begin_src lisp
  CL-USER> (ql:quickload :codegrader)  ; Loading the codegrader
  CL-USER> (cg:grade-code "/home/John/mysol.lisp" "/home/John/test-cases.lisp") 
  ("100.0" OK "No runtime errors"
   (("Pass" T TEST-DEPOSIT (EQUAL (DEPOSIT 20) 130))
    ("Pass" T TEST-DEPOSIT (EQUAL (DEPOSIT 10) 110))
    ("Pass" T TEST-DEPOSIT (NOT (DEPOSIT 10001)))
    ("Pass" T TEST-WITHDRAW (EQUAL (WITHDRAW 60) 10))
    ("Pass" T TEST-WITHDRAW (NOT (WITHDRAW 80)))
    ("Pass" T TEST-WITHDRAW (NOT (WITHDRAW 10001)))
    ("Pass" T TEST-WITHDRAW (EQUAL (WITHDRAW 20) 70))
    ("Pass" T TEST-WITHDRAW (EQUAL (WITHDRAW 10) 90))))
  GRADER> (in-package :CL-USER)
  CL-USER> 
#+end_src

* License and Credits

See LICENSE for usage permissions. See AUTHORS for credits.




