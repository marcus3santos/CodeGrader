#+TITLE: CodeGrader

CodeGrader is an automated grader for lisp programming practicum
assessments.


* Dependencies

- Follow the instructions available [[https://marcus3santos.github.io/lisp-ide.html][here to install the Lisp programming environment]].
  
* Installation

Type the commands below an a linux or Mac terminal:
  #+begin_src shell
   cd ~/quicklisp/local-projects/
   git clone https://github.com/marcus3santos/codegrader.git  
  #+end_src

* Usage

** Marking

*** Preamble


CodeGrader is able to mark students' solutions that have been
downloaded from D2L as a zip file, or solutions that have been saved
in the computer where the student took the test. For this tutorial, we
assume the latter. 

We also assume there is zip archive file containing the students' solutions originally stored in specific folders named
*cps05YY/engXXX-ZZ/pt/* or *cps305YY/otest-KK*, where *YY* is the course section number and *KK* is an integer number,
*engXX* is the lab room number, and *engXXX-ZZ* is the computer's ID
number. For example, suppose one student from section 05 took the exam
in lab room ENG203 on a PC whose ID is eng203-03, and another student
from section 08 took the same version of the exam in at the Accommodation Test Centre 
on a PC whose ID is otest-07. Then, the diagram below represents the
corresponding file structure where the two Lisp files containing the
solutions for each student have been stored:
   - cps30505/eng203-03/pt/
     - q1.lisp
     - q2.lisp
   - cps30508/otest-07/pt/
     - q1.lisp
     - q2.lisp

Here is the command the IT staff used to create the zip file:
#+begin_src shell
zip -r cps305mocktest.zip cps305mocktest/cps305*/eng*/ cps305mocktest/cps305*/otest*/-x '*/.*' '*/quicklisp/*' '*/Cheatsheet-emacs.pdf' '*/paredit.pdf' '*/test.pdf'
#+end_src

*** Steps for grading students' solutions

1. *Create a zipped file containing the students' solutions*: Since
   students from specific sections may have taken different versions
   of the exam, it is crucial to obtain the sections-to-exam-versions
   mapping in advance from the course coordinator to ensure you are running
   CodeGrader  on the solutions written by the students in the correct section, and
   using the correct test cases for the respective exam version.  For
   example, suppose students from sections 03 and 05 are taught by instructor A and took Version 1 of
   the exam, and students from section 10 are taught by instructor B and took Version 2. 

   Assume the parent folder *~/tmp/cps305PracticumTest/* contains the students' solutions from the various sections. Also assume you want to store the zip archive for sections 03 and 05
   in *~/tmp/PT1/Sections/03-05/* (you have already created that folder), the commands below show how to
   create the zip file with the solutions of the students from sectoins 03 and 05:
   #+begin_src shell
     cd ~/tmp/cps305PracticumTest
     (cd cps30503 && zip -r ~/tmp/PT1/Sections/03-05/std-sol.zip *) && (cd cps30505 && zip -r ~/tmp/PT1/Sections/03-05/std-sol.zip *)
   #+end_src
   You would do something similar to zip the solutions for students in section 10.
   #+begin_src shell
     cd ~/tmp/cps305PracticumTest/cps30510
     zip -r ~/tmp/PT1/Sections/10/std-sol.zip 
   #+end_src
   By zipping this way, you would create a zip archive that does not
   include the parent directories (cps30505 and cps30508); it only
   includes the eng*/ and otest*/ folders in your zip archive.

2. *Create a CSV file containing the mapping of students-to-computers*:
   We assume the IT technicians have sent you CSV files containing the
   student-to-computer mapping for each of the course sections. Now,
   based on these CSV files and on the sections-to-exams-versions, you
   should create a CSV file that contains the mappings of all students
   who took a given test version. Each row in that
   spreadsheet should contain the following information: Student ID
   number, Student First Name, Student Last Name, and Room-PC ID
3. *Prepate the test cases*: Prepare a folder containing the *test
   cases lisp files* for the assignment you want to mark. You can find
   folders with test case files for CPS305 Practice Lab Exercises in
   the Test-Cases directory of this repository.
4. Create a folder where CodeGrader will store the results. You can give any name to that folder.
5. [ /This is step is not necessary if you are assessing an "ungraded" examination (i.e., an assessment
   whose weight is zero)/ ] On D2L, export the students' *assignment grades* *to a CSV
   file*. Note the following when generating this file
   - Select the following /Export Options/:
     - Key Field:
       - *Both*
     - Grade Values:
       - *Points grade*
     - User Details: 
       - *Last name*
       - *First name*
  - /Choose grades to Export/: Choose only one of the listed grade items. If the grade item contains subitems, choose the appropriate subitem. For example: if a /Practicum Test/ grade item contains subitems representing the versions of the test, choose the subitem representing the Practicum Test version you are interested in grading.
  Below is an example of a CSV file exported by D2L:
  #+begin_example
     OrgDefinedId,Username,Last Name,First Name,Practicum Test 1 - Version 1 Points Grade <Numeric MaxPoints:100 Weight:10 Category:Practicum Test 1 CategoryWeight:10>,End-of-Line Indicator
     #500583619,#TTiger,Tigertongue,Tim,,#
     #500585612,#Patrick97,Pearson,Patrick,,#
     #501585619,#Towhander,Twohands,Tony,,#
     #500586619,#Zain1997,Zodson,Zain,,#
     #500585619,#Coopercat,Cooper,Cain,,#
     #500585119,#Hammermann,Odinson,Thor,,#
  #+end_example
  For more information, visit [[https://www.torontomu.ca/courses/instructors/tutorials/grades/grades-export-import/]]
6. Launch sbcl from the command line
   #+begin_src shell
     rlwrap sbcl --dynamic-space-size 20480
   #+end_src
7. To load the codegrader, type the following commands on the REPL:
   #+begin_src lisp
          (ql:quickload :codegrader)
   #+end_src
8. To run the students' solutions through CodeGrader, type the command
   below on the CodeGrader REPL: (NOTE: once you launch CodeGrader, it
   will start executing the students' solutions; consequently, it will
   display on the REPL buffer all error/warning messages and output
   generated by the student's solution. CodeGrader will be done
   marking when you see the message =Exam grading complete!= displayed
   on the REPL window buffer.)
   #+begin_src lisp
      (cg:grade-exam submissions map tests-folder results-folder exam-grades-export-file)
   #+end_src
   where:
   - ~submissions~ is a string representing the full path and name of
     the zipped file containing the students' solutions, e.g.,
     ~/Users/johndoe/Zipped-solutions/std-sol.zip~
   - ~map~  is a string representing the full path and name of of the csv file storing the student-to-pc mapping.
   - ~test-folder~ is a string representing the full path for the test cases folder.
   - ~results-folder~ is a string representing the full path for a folder
    where you want codegrader to store the results (the students'
    marks and log files). For example, if you provide the path
    #+begin_example
    "/Users/johndoe/A1/"
    #+end_example
    then CodeGrader will create its
    files/subfolders inside folder ~/Users/johndoe/A1/~.
   - (optional) ~exam-grades-export-file~ is a string representing the full path for
     the D2L exam grades exported by D2L

*** If a student's solution causes a Stack Overflow and crashes CodeGrader
While Codegrader is running each student's solution on the test cases it displays, among other things, a message providing information about the student:
#+begin_example
...
Running program of student (50123456 John Doe eng205-08)
...
#+end_example
If a student's solution crashes CodeGrader because of a stack overflow, do the following to enable CodeGrader to continue marking the solutions:
1. If CodeGrader has crashed, scroll up and look for the last printed 'Running program ...etc' message and take note of the student's number and name.
2. Remove that student from the mapping (csv) file, save the file,  and put them in a "problematic.csv" file
3. Run codegrader again.
4. If code grader crashed,  goto step 1.
5. If codegrader completed the grading without crashing, manually evaluate the solutions in the problematic.csv file using  the function call below *on each pair* of solution and test case files *pt/qi.lisp* , *Test-cases/qi.lisp*.

#+begin_src lisp
(grader:evaluate-solution <solution-file> <test-case-file>)
#+end_src 
Where:
- =<solution-file>= is a string containing the full path to the student solution *pt/qi.lisp*
- =<test-case-file>= is a string containing the full path to the respective test case *Test-case/qi.lisp*

The function above returns a list containing the result of the evaluation. The first item in the list is the number of points CodeGrader assessed for that solution, the last item is the feedback. If a solution caused a stack overflow and crashed CodeGrader, you will take note that that you need to assign zero points to that student's solution and the respective feedbac is "CAUSED A STACK OVERFLOW DUE TO ENDLESS RECURSION."

The student's mark is the sum of the points of the evaluations of all solution files divided by the number of solution files. For example, if a solution for a question consists of files *q1.lisp*, *q2.lisp*, and *q3.lisp* and the sum of the points assessed by Codegrader is 70. Then the student's mark should be 70/3. 

Create a feedback file by copy-pasting the above information as appropriate to a file and name that file by hashing the student ID using that function below:
#+begin_src lisp
(defun my-feedback-file (stdid)
  (format nil "~A.txt" (sxhash (format nil "~A" stdid))))
#+end_src

Add that file to the *Feedback* folder created by CodeGarder, and enter the student's mark in the *grades.csv* file (see Section Output below).
    
** Output

CodeGrader generates the following files in the =results= folder (see above):
- A csv spreadsheet file called ~grades.csv~  This is a D2L-importable
  grades file and it is created based on the ~exam-grades-export-file~ argument optionally
  provided by the user (see items 1 and 2 above). Below is an example of
  such files:
   #+begin_example
   Username,Last Name,First Name,Lab 0X Points Grade <Course Data>,End-of-Line-Indicator
   #TTiger,Tigertongue,Tim,100.0,# 
   #Patrick97,Pearson,Patrick,72.5,#
   #Towhander,Twohands,Tony,100.0,#
   #Zain1997,Zodson,Zain,95.5,#
   #Coopercat,Cooper,Cain,100.0,#
   #Hammermann,Odinson,Thor,0.0,#
   #+end_example
   Note:
   - If a student exists in the exported file but not in the
     submissions folder, then the respective grades will
     not be included in the generated in the respective csv files.
- A Feedback folder that holds feedback files for the students. The
  general structure is like this: Consider Timb Handerson who did not
  get a full grade. His feedback file will be as such:
  #+begin_example
  Feedback on your assignment solution

  Unit test results:
  
  ((Pass TEST-DEPOSIT (EQUAL (DEPOSIT 20) 130))
   (Pass TEST-DEPOSIT (EQUAL (DEPOSIT 10) 110))
   (Pass TEST-DEPOSIT (NOT (DEPOSIT 10001)))
   (Fail TEST-WITHDRAW (EQUAL (WITHDRAW 60) 10))
   (Pass TEST-WITHDRAW (NOT (WITHDRAW 80)))
   (Pass TEST-WITHDRAW (NOT (WITHDRAW 10001)))
   (Fail TEST-WITHDRAW (EQUAL (WITHDRAW 20) 70))
   (Fail TEST-WITHDRAW (EQUAL (WITHDRAW 10) 90)))
  #+end_example

The log file *codegrader-history/log.txt* located in the root of the
user's home directory contains historical information about the
evaluation of students' assignments.

** Test cases
Test cases must follow a specific format and have a specific file name
in order to be used within CodeGrader.  As an example, suppose the
exam requires the students to submit a file called *q1.lisp* that
includes two functions: a ~fact~ function that gives the factorial of
a number, and a ~avg~ function that gives the average of a list of
numbers. Moreover, suppose also that in certain questions, the use of
specific Lisp symbols is restricted, e.g., FIND and
COUNT. If students use any of these prohibited symbols, a penalty of
90% will be deducted from their total marks for that question. Then,
the test cases lisp file will be something like this:
#+begin_src lisp
  (forbidden-symbols :penalty 0.90 :symbols '(find count))
  
  (deftest test-fact ()
    (check
      (equal (fact 5) 120)
      (equal (fact 6) 720)
      (equal (fact 7) 5040)
  
  (deftest test-avg ()
    (check
      (equal (avg '(5 8 10 2 12)) 7.4)
      (equal (avg '(0 0 0 0 0 0)) 0)
      (equal (avg '(1 2 0)) 1)
  
  (defun unit-test ()
    "Calls the test cases and 'forgets' the functions that were tested."
    (test-fact)
    (fmakunbound 'fact) ; Removes the function definition from the global environment,
                        ; so the next time around the unit test is done on a freshly loaded version of this function.
    (test-avg)
    (fmakunbound 'avg))
  
  (unit-test) 
#+end_src
Notice: you can include more complex forms of tests, but the general idea is that each argument of CHECK has to be a selfcontained form, i.e., any variables used in it should be defined within the form. For example, below is a test case for a function HT-DELETE that deletes an item from a hash table
#+begin_src lisp
(deftest test-ht-delete ()
  (check
    (equal (let ((*ht* (ht-create '((1 1) (2 2) (3 3) (4 4) (5 5) (6 6)))))
	     (ht-delete 4 *ht*)
	     (ht-get 4 *ht*))  ; accessing a deleted item
	   nil)
    (equal (let ((*ht* (ht-create '((1 1) (2 2) (3 3) (4 4) (5 5) (6 6)))))
	     (ht-delete 4 *ht*)
	     (ht-delete 4 *ht*))  ; deleting an already deleted item
	   nil)
    (equal (let ((*ht* (ht-create '((1 1) (2 2) (3 3) (4 4) (5 5) (6 6)))))
	     (ht-add "a" 44 *ht*)
	     (ht-delete "a" *ht*))  
	   44)))
  
#+end_src

Any errors that the student's solution could raise during runtime will
be handled by CodeGrader and reported as appropriate.

** Other functions

*** Marking all the program files submitted by a student

In case you wish to mark all the program files submitted by a student, you can use the following function:
#+begin_example
eval-student-solutions (std-id solutions-folder test-cases-folder output-folder)
evaluate-solution (student-solution test-cases-dir)
---------------------------------------------------
Description:  Based on the given student id (std-id, an integer), the students' solutions in solutions-folder, and 
              the test cases in test-cases-folder, generates a file in the output-folder containing the CodeGrader-generated feedback.
Inputs:       1) std-id [integer]: The student id number
              2) solutions-folder [string]: the full path of the folder containing the student's program files
              3) test-cases-folder [string]: The folder containing the test cases files.
              4) output-folder [string]: An existing folder where the generated feedback file will be saved

Outputs:      
              [string] A message informing where the feedback file has been saved.
---------------------------------------------------
#+end_example

Usage Example: John is a student whose ID is 1234. Say you needed to
autograde John's solutions stored in =/home/John/Solutions/=. The test
cases are stored in =/home/John/Test-cases/=, and you want to store the feedback in =/home/John/Results/=
#+begin_src lisp
  CL-USER> (ql:quickload :codegrader)  ; Loading the codegrader
  CL-USER> (cg:eval-student-solutions "/home/John/Solutions/" "/home/John/Test-cases/" "/home/John/Results/")
  Feedback saved in /home/John/Results/3753443020201070578.txt
  CL-USER> 
#+end_src


*** Marking one program file submitted by a student
In case you wish to mark one specific submission or test your test
case file, you can use the following function:
#+begin_example
evaluate-solution (student-solution test-cases-dir)
---------------------------------------------------
Description:  Loads the student-solution file, loads the test cases, runs
              the test cases, and returns the percentage of correct results over total results

Inputs:       1) student-solution [string]: The directory for the solution of the student.
              2) test-cases-dir [string]: The directory for the test cases file. This will be used to test the solution of the students for the current assignment.

Outputs:      [list] A list of the following:
              1) [string] The grade of the student.
              2) [string] A comment that describes if there was a runtime error while loading the student submission or not
              3) [string] A description of what happened during runtime (from exceptions to conditions to whatever) 
              4) [list] The results of marking each of the test cases.

Side-effects: This function utilizes the global variable *results* while running. In the beginning by reseting it to nil, and at the end by updating it with the current
              student's submission results.
---------------------------------------------------
#+end_example

Usage Example: Say there was a student that you want to mark their
submissions independantly from the other students. You can simply take
their lisp submission file, say ~"/home/John/mysol.lisp"~ , and the
test cases lisp file "/home/john/test-cases.lisp"~. You would use 
CodeGrader as follows: (assuming you have already installed CodeGrader
as shown above)
#+begin_src lisp
  CL-USER> (ql:quickload :codegrader)  ; Loading the codegrader
  CL-USER> (cg:evaluate-solution "/home/John/mysol.lisp" "/home/John/test-cases.lisp") 
  ("100.0" OK "No runtime errors"
   (("Pass" T TEST-DEPOSIT (EQUAL (DEPOSIT 20) 130))
    ("Pass" T TEST-DEPOSIT (EQUAL (DEPOSIT 10) 110))
    ("Pass" T TEST-DEPOSIT (NOT (DEPOSIT 10001)))
    ("Pass" T TEST-WITHDRAW (EQUAL (WITHDRAW 60) 10))
    ("Pass" T TEST-WITHDRAW (NOT (WITHDRAW 80)))
    ("Pass" T TEST-WITHDRAW (NOT (WITHDRAW 10001)))
    ("Pass" T TEST-WITHDRAW (EQUAL (WITHDRAW 20) 70))
    ("Pass" T TEST-WITHDRAW (EQUAL (WITHDRAW 10) 90))))
  GRADER> (in-package :CL-USER)
  CL-USER> 
#+end_src


* Sandboxing (DRAFT) - Package Structure for Exporting Functions to test-runtime

To structure the packages such that the student's packages (`q1`, `q2`, etc.) export specific functions to a `test-runtime` package, the following hierarchy is defined:

**Strategy**
1. Define the `:sandbox` package:
   - Implements restrictions on system-level access.
2. Define student packages (`:q1`, `:q2`, etc.):
   - Inherit from `:sandbox`.
   - Export only specific functions to be visible in `:test-runtime`.
3. Define the `:test-runtime` package:
   - Uses student packages to access their exported functions.
4. Control exports to maintain encapsulation.

**Implementation**

*** :sandbox Package
#+begin_src lisp
(defpackage :sandbox
  (:use :cl)
  (:shadow "OPEN" "LOAD" "EVAL" "DELETE-FILE")) ; Shadow restricted functions

(in-package :sandbox)

(defun open (path &key (direction :input) &allow-other-keys)
  (error "Access to OPEN is restricted in the sandbox."))

(defun load (path &key &allow-other-keys)
  (error "Access to LOAD is restricted in the sandbox."))

(defun eval (form)
  (error "Access to EVAL is restricted in the sandbox."))

(defun delete-file (path)
  (error "Access to DELETE-FILE is restricted in the sandbox."))

(defun sandbox-message ()
  (format t "You are working in the sandbox environment.~%"))
#+end_src

*** :q1 Package (Student Implementation)
#+begin_src lisp
(defpackage :q1
  (:use :sandbox)
  (:export :solve-q1))  ; Export only the solve-q1 function

(in-package :q1)

(defun solve-q1 ()
  (format t "Solving Question 1~%"))
#+end_src

*** :q2 Package (Student Implementation)
#+begin_src lisp
(defpackage :q2
  (:use :sandbox)
  (:export :solve-q2))  ; Export only the solve-q2 function

(in-package :q2)

(defun solve-q2 ()
  (format t "Solving Question 2~%"))
#+end_src

*** :test-runtime Package
#+begin_src lisp
(defpackage :test-runtime
  (:use :cl :q1 :q2))  ; Use the student packages to access their exported functions

(in-package :test-runtime)

(defun test-all ()
  (solve-q1)  ; Call exported function from :q1
  (solve-q2)) ; Call exported function from :q2
#+end_src

** Workflow

*** Student Workflow
- Students implement their solutions in `:q1`, `:q2`, etc.
- Ensure only required functions are exported.

*** Test Runtime Workflow
- `:test-runtime` accesses exported functions from student packages.
- Test scripts ensure encapsulation.

** Example Usage

*** Question 1 Student File
#+begin_src lisp
(in-package :q1)

(defun solve-q1 ()
  (format t "Solving Question 1~%"))
#+end_src

*** Question 2 Student File
#+begin_src lisp
(in-package :q2)

(defun solve-q2 ()
  (format t "Solving Question 2~%"))
#+end_src

*** Test Runtime File
#+begin_src lisp
(in-package :test-runtime)

(defun test-all ()
  (solve-q1)  ; Allowed, since solve-q1 is exported
  (solve-q2)) ; Allowed, since solve-q2 is exported
#+end_src

*** Running the Test
#+begin_src lisp
(test-all)
; Output:
; Solving Question 1
; Solving Question 2
#+end_src

** Benefits
- **Encapsulation**: Only necessary functions are exported, hiding internal details.
- **Reusability**: `:test-runtime` focuses on testing with a consistent interface.
- **Flexibility**: Additional student packages (`:q3`, etc.) can be added without modifying the structure.


* License and Credits

See LICENSE for usage permissions. See AUTHORS for credits.




